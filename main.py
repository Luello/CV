import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import PCA
import numpy as np
import ast
import plotly.express as px
import re
from collections import Counter
st.set_page_config(layout="wide")
st.markdown("""
    <style>
        /* Agrandir le texte dans les boutons radio de la sidebar */
        section[data-testid="stSidebar"] .stRadio > label {
            font-size: 1.2rem;
            font-weight: 500;
        }

        /* Bonus : ic√¥nes emoji un peu plus espac√©es */
        section[data-testid="stSidebar"] .stRadio div {
            padding-top: 0.4rem;
            padding-bottom: 0.4rem;
        }
    </style>
""", unsafe_allow_html=True)
# Configuration de la page en mode large


# Panneau lat√©ral
page = st.sidebar.radio("üìÅ Navigation :", [
    "üè† Accueil",
    "üìà D√©mo - Visualisations",
    "‚ñ∂Ô∏è NLP: Analyse de l'identit√© politique des influenceurs Youtube",
    "üéµ NLP/LLM: Cartographier les artistes fran√ßais depuis les paroles de leur r√©pertoire."
])
if page== "üìà D√©mo - Visualisations":
    st.title("üìä Visualisations r√©alis√©es avec les donn√©es Data.gouv sur les accidents routiers.")

    # Int√©gration de l'iframe Infogram
    infogram_html = """
<div class="infogram-embed" data-id="8b9c87b0-eb40-4411-927d-1141a21b8c59" 
     data-type="interactive" data-title=""></div>
<script>
!function(e,n,i,s){
    var d="InfogramEmbeds";
    var o=e.getElementsByTagName(n)[0];
    if(window[d] && window[d].initialized) {
        window[d].process && window[d].process();
    } else if(!e.getElementById(i)){
        var r=e.createElement(n);
        r.async=1;
        r.id=i;
        r.src=s;
        o.parentNode.insertBefore(r,o);
    }
}(document,"script","infogram-async","https://e.infogram.com/js/dist/embed-loader-min.js");
</script>

<div style="padding:8px 0;font-family:Arial!important;font-size:13px!important;
line-height:15px!important;text-align:center;border-top:1px solid #dadada;
margin:0 30px">
<br><a href="https://infogram.com" style="color:#989898!important;
text-decoration:none!important;" target="_blank" rel="nofollow">Infogram</a></div>
"""

    
    st.components.v1.html(infogram_html, height=800, scrolling=True)
    
    # Ajout du cr√©dit Infogram (facultatif)
    st.markdown(
        '<div style="padding:8px 0;font-family:Arial!important;font-size:13px!important;'
        'line-height:15px!important;text-align:center;border-top:1px solid #dadada;'
        'margin:0 30px;width: 640px">'
        '<br><a href="https://infogram.com" style="color:#989898!important;'
        'text-decoration:none!important;" target="_blank" rel="nofollow">Infogram</a></div>',
        unsafe_allow_html=True
    )
if page == "üè† Accueil":
    st.markdown('<h1 style="text-align: center;">Bienvenue sur mon CV applicatif</h1><br>', unsafe_allow_html=True)
    # Utiliser les colonnes de Streamlit pour centrer les √©l√©ments
    col1, col2, col3 = st.columns([1, 2,1])  # Diviser l'espace en trois colonnes
    
    with col1:
        st.image("photo.jpg", width=250,use_column_width='always')
    with col2:  # Centrer les √©l√©ments en les pla√ßant dans la colonne centrale
        # Titre
        
        st.markdown('<h1 style="text-align: center;">Th√©o Bernad</h1><br>', unsafe_allow_html=True)
        
        
        

        # Description principale
        st.markdown(
            """
            <div style="text-align: center; font-size: 18px; line-height: 1.6; margin-top: 20px;">
                <p>Data Scientist passionn√© par les opportunit√©s qu'offrent les progr√®s en IA.</p>  
                <p>Je peux mener un projet Data du besoin m√©tier au d√©ploiement, dans une optique "full-stack".</p>
                <p> Vous pouvez acc√©der, depuis le menu de gauche, aux diff√©rents projets que j'ai pu r√©aliser, et dont je d√©ploie une partie ici.</p>
            </div><br>
            """, 
            unsafe_allow_html=True
        )

    # Cr√©er les onglets
    tab1, tab2, tab3 = st.tabs(["Exp√©riences", "Formations","Passions"])

    # Contenu de chaque onglet
    with tab3:
        col1, col2 = st.columns([1,1])
        with col1:
            st.markdown(
                """
                <div style="text-align: left; font-size: 18px; line-height: 1.6; margin-top: 20px;">
                    <p>Quelques domaines de la Data dont les th√©matiques me passionnent:</p>
                    <ul style="list-style-position: inside; text-align: left; display: inline-block;">
                        <li>√âtudes sociologiques et comportementales</li>
                        <li>Analyse des Gameplays dans le sport ou les jeux vid√©o</li>
                        <li>Projets autour de la cognition et des imageries c√©r√©brales</li>
                        <li>Domotiques et agents intelligents</li>
                    </ul>
                </div><br>
                """, 
                unsafe_allow_html=True
            )
        with col2:
            st.markdown(
                """
                <div style="text-align: left; font-size: 18px; line-height: 1.6; margin-top: 20px;">
                    <p> D'autres int√©r√™ts que j'ai dans la vie : </p>
                    <ul style="list-style-position: inside; text-align: left; display: inline-block;">
                        <li> Escalade, Boxe, Escrime</li>
                        <li> Cin√©ma, Histoire, Philosophie, Cuisine,   </li>
                        <li> Les nouvelles technologies et leurs implications</li>
                        <li> Jeux historiques de strat√©gie </li>
                    </ul>
                </div><br>
                """, 
                unsafe_allow_html=True
            )

    with tab1:
        st.markdown(
            """
            <div style="text-align: left; font-size: 18px; line-height: 1.6; margin-top: 20px;">
                <p><strong>Exp√©riences professionnelles:</strong></p>
                <ul style="list-style-position: inside; text-align: left; display: inline-block;">
                    <li><strong>Data Scientist - Marine Nationale (Tours)</strong>
                        <ul style="margin-left: 20px; list-style-type: disc;">
                            <li>Projet IA de pr√©diction sur une th√©matique RH</li>
                            <li>Traitement, reconstitution et cr√©ation de donn√©es</li>
                            <li>Analyse BI (Dashboard QlikSense)</li>
                            <li>Am√©lioration des processus Data (VBA, UIPATH, Python)</li>
                            <li>Accompagnement structurel au traitement et √† la politique des donn√©es</li>
                        </ul>
                        <p style="margin-left: 20px;"><em>Soft Skills principaux :</em> Autonomie, gestion de projet, √©coute des besoins, cr√©ativit√©, rigueur</p>
                    </li>
                    <br>
                    <li><strong>Data Analyst - Gowod (Montpellier)</strong>
                        <ul style="margin-left: 20px; list-style-type: disc;">
                            <li>Analyse et visualisation sur le comportement des utilisateurs d'une application sportive</li>
                            <li>Analyses RFM / BI, strat√©gies marketing</li>
                        </ul>
                        <p style="margin-left: 20px;"><em>Soft Skills principaux :</em> Travail en √©quipe, vision marketing, appr√©hension d'une Base de donn√©es complexe</p>
                    </li>
                    <br>
                    <li><strong>Assistant p√©dagogique - Lyc√©e Marcel Sembat (Lyon)</strong>
                        <ul style="margin-left: 20px; list-style-type: disc;">
                            <li>Accompagnement p√©dagogique des √©l√®ves</li>
                            <li>Projet p√©dagogique contre le d√©crochage scolaire</li>
                        </ul>
                        <p style="margin-left: 20px;"><em>Soft Skills principaux :</em> Adaptabilit√©, sociabilit√©, p√©dagogie, patience</p>
                    </li>
                    <br>
                    <li><strong>Remplacements √©ducatifs - IME Pierre de Lune (Lyon)</strong>
                        <ul style="margin-left: 20px; list-style-type: disc;">
                            <li>Accompagnement quotidien d'enfants en situation d'handicap</li>
                        </ul>
                        <p style="margin-left: 20px;"><em>Soft Skills principaux :</em> Patience, r√©activit√©, Travail d'√©quipe, gestion de crise</p>
                    </li>
                    <br>
                    <li><strong>Autres exp√©riences constructives:</strong>
                        <ul style="margin-left: 20px; list-style-type: disc;">
                            <li>Vendanges</li>
                            <li>T√©l√©vente</li>
                            <li>R√©novation d'int√©rieur</li>
                            <li>Gestion d'une auberge de jeunesse</li>
                        </ul>
                        <p style="margin-left: 20px;"><em>Soft Skills principaux :</em> Adaptabilit√©, t√©nacit√©, curiosit√©</p>
                    </li>
                </ul>
            </div><br>
            """, 
            unsafe_allow_html=True
        )

    with tab2:
        st.markdown(
            """
            <div style="text-align: left; font-size: 18px; line-height: 1.6; margin-top: 20px;">
                <p><strong>Formations :</strong></p>
                <ul style="list-style-position: inside; text-align: left; display: inline-block;">
                    <li><strong>Data Scientist - Marine Nationale / WCS (2023)</strong>
                        <ul style="margin-left: 20px; list-style-type: disc;">
                            <li>Projets de Machine learning: Pr√©diction, Classification, Clustering, m√©thodes de Bagging/Boosting, mod√©lisation de s√©ries temporelles, m√©thodes ensemblistes...</li>
                            <li>R√©seaux de neurones: CNN, RNN, LSTM : Python, TensorFlow, Keras, Scikit-learn</li>
                            <li>Outils de collaboration et de production : Git, Docker, Terminal</li>
                            <li>D√©veloppement d'application : Django, FastAPI, CSS, HTML</li>
                            <li>Statistiques et fondamentaux math√©matiques : tests statistiques, distributions...</li>
                            <li>Gestion de projets & Travail d'√©quipe</li>
                        </ul>
                        <p style="margin-left: 20px;"><em>J'y ai valid√© une certification professionnelle "Concepteur D√©veloppeur d'application" (Niveau 6)</em></p>
                    </li>
                    <br>
                    <li><strong>Data Analyst - WCS (Lyon - 2022)</strong>
                        <ul style="margin-left: 20px; list-style-type: disc;">
                            <li>Codage et traitement de donn√©es en Python (mon outil principal) : Pandas, NumPy, Matplotlib, Plotly, SciPy, BeautifulSoup</li>
                            <li>D√©veloppement de diff√©rentes applications Streamlit √† des fins d'analyses ou de classifications : Scikit-learn, TensorFlow, PyTorch, Streamlit, Datapane</li>
                            <li>Sp√©cialisation en machine learning : Projet de pr√©diction du vainqueur d'un duel tennistique depuis des donn√©es sur le style de jeu et l'historicit√© des joueurs</li>
                        </ul>
                        <p style="margin-left: 20px;"><em>Formation de 8 mois pour approfondir une base solide de la manipulation des donn√©es et de leurs analyses</em></p>
                    </li>
                    <br>
                    <ul style="text-align: center;"><strong>Je me sp√©cialise √† ce moment l√† dans la Data!</strong></ul>
                    <br>
                    <li><strong>Master en Science politique - Enqu√™tes et analyse des processus politiques (Lyon - 2020)</strong>
                        <ul style="margin-left: 20px; list-style-type: disc;">
                            <li>Stage de terrain : √©coute active et recueil d'√©l√©ments pour une √©tude</li>
                            <li>Focales √âpist√©mologie, Sociologie de l'action publique, expertise internationale</li>
                            <li>R√©daction d'un m√©moire de recherche de 130 pages sur le rapport au politique des √©ducateurs</li>
                        </ul>
                        <p style="margin-left: 20px;"><em>M'a permis d'approfondir l'√©tude des processus politiques aux √©chelles structurelles ou individuelles, et leurs implications. Un atout significatif pour situer les acteurs, les enjeux, les institutions dans tous les contextes. Synth√©tiser, construire une Strat√©gie.</em></p>
                    </li>
                    <br>
                    <li><strong>Licence en sciences cognitives, r√©alis√©e en m√™me temps que le master en science politique (Lyon - 2020)</strong>
                        <ul style="margin-left: 20px; list-style-type: disc;">
                            <li>√âtude des m√©canismes cognitifs : M√©moire, attention, langage, √©motions, raisonnement, action</li>
                            <li>Apports concrets en neuro-imagerie, plasticit√© c√©r√©brale, neuroproth√®ses</li>
                            <li>Programmation : cognition artificielle, Python</li>
                        </ul>
                        <p style="margin-left: 20px;"><em>Les apports significatifs de cette discipline √©mergente m'ont familiaris√© avec ses enjeux, ses m√©thodes et ses ambitions.</em></p>
                    </li>
                </ul>
            </div><br>
            """, 
            unsafe_allow_html=True
        )
        # Contact en bas de page
    st.markdown('<br><br><br><h2 style="text-align: center;">Contact</h2>', unsafe_allow_html=True)

    # Centrer les liens et le bouton de t√©l√©chargement
    col1, col2, col3 = st.columns([1, 2, 1])    
    with col2:
        st.markdown(
    '<div style="text-align: center; margin-top: 20px;">'  # Ajoute un espacement au-dessus
    '<a href="https://www.linkedin.com/in/theobcd/" style="display: block; margin-bottom: 10px;">LinkedIn</a>'  # Chaque lien sur une nouvelle ligne avec un espacement en bas
    '<a href="https://github.com/Luello" style="display: block; margin-bottom: 10px;">GitHub</a>'  # Ajoute un espacement en bas
    '</div>', 
    unsafe_allow_html=True
)

    # Bouton pour t√©l√©charger le CV centr√©
    file_path = "CV DATA SCIENTIST- BERNAD THEO.pdf"
    try:
        with open(file_path, "rb") as file:
            st.markdown('<div style="text-align: center; margin-top: 10px;">', unsafe_allow_html=True)  # Nouvelle div pour le bouton
            st.download_button(
                label="T√©l√©charger mon CV",
                data=file,
                file_name="CV_DATA_SCIENTIST_BERNAD_THEO.pdf",  # nom du fichier √† t√©l√©charger
                mime="application/pdf"  # type MIME pour un fichier PDF
            )
            st.markdown('</div>', unsafe_allow_html=True)  # Ferme la div pour le bouton
    except FileNotFoundError:
        st.error("Le fichier n'a pas √©t√© trouv√©. V√©rifiez le chemin et le nom du fichier.")


elif page== "‚ñ∂Ô∏è NLP: Analyse de l'identit√© politique des influenceurs Youtube":
    import pandas as pd
    import numpy as np
    from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler
    from umap import UMAP
    import plotly.express as px
    import streamlit as st
    import ast

    st.title("üìä Projection UMAP des cha√Ænes YouTube selon leur identit√© politique")

  import pandas as pd
import streamlit as st

st.markdown("""
### üß† Objectif

Cette visualisation cherche √† repr√©senter l'identit√© politique des influenceurs YouTube √† partir de plusieurs dimensions qualitatives et quantitatives extraites de leurs discours.

Ce graphique illustre comment une analyse NLP peut combiner **quantitatif** et **qualitatif** pour appr√©hender des logiques politiques implicites dans les scripts vid√©os.

Un **LLM** analyse les scripts et extrait automatiquement un ensemble de **descripteurs discursifs, id√©ologiques et narratifs**.
""")

# Construction du tableau descripteurs
descripteurs = [
    ("format_detecte", "Type pr√©cis de vid√©o", "d√©bat, vlog, podcast, analyse politique‚Ä¶"),
    ("ton_general", "Ton dominant du discours", "neutre, pol√©mique, acad√©mique, humoristique‚Ä¶"),
    ("registre_discursif", "Type discursif", "explicatif, militant, scientifique, complotiste‚Ä¶"),
    ("strat√©gie_argumentative", "Strat√©gie argumentative", "d√©monstratif, √©motionnel, narratif‚Ä¶"),
    ("structure_narrative", "Organisation narrative", "lin√©aire, chaotique, r√©currente‚Ä¶"),
    ("style_de_politisation", "Forme de politisation", "rationnel, affectif, moraliste‚Ä¶"),
    ("valeurs_invoqu√©es", "Valeurs mises en avant", "libert√©, √©galit√©, nation, m√©ritocratie‚Ä¶"),
    ("th√©matiques_dominantes", "Th√®mes principaux", "√©ducation, immigration, √©cologie‚Ä¶"),
    ("cibles_implicites", "Cibles id√©ologiques", "√©lites, m√©dias, gouvernement, minorit√©s‚Ä¶"),
    ("r√©f√©rences_implicites", "R√©f√©rences culturelles", "Zemmour, Orwell, Deleuze‚Ä¶"),
    ("axe_latent", "Cadres id√©ologiques", "technocratie, souverainisme, socialisme‚Ä¶"),
    ("conception_du_nous", "Collectif valoris√©", "peuple, citoyens, communaut√©, nation‚Ä¶"),
    ("positionnement_soci√©tal", "Rapport √† la soci√©t√©", "critique des √©lites, d√©fense d‚Äôun groupe‚Ä¶"),
    ("cadre_problematisation", "Fa√ßon de poser les enjeux", "syst√®me en crise, injustice sociale‚Ä¶"),
    ("figures_ennemies", "Adversaires implicites", "le syst√®me, les mondialistes‚Ä¶"),
    ("r√©cit_id√©ologique", "Narration politique", "d√©clin civilisationnel, peuple trahi‚Ä¶"),
    ("axes_de_tension", "Axes de conflit", "√©lite vs peuple, progr√®s vs tradition‚Ä¶"),
    ("paradigmes_compatibles", "Paradigmes compatibles", "lib√©ralisme, anarchisme, gaullisme‚Ä¶"),
    ("ton_politique", "Ton politique", "engag√©, militant, distant‚Ä¶"),
    ("enjeux_sociaux_centr√©s", "Enjeux sociaux centraux", "sant√©, s√©curit√©, inclusion‚Ä¶"),
    ("charge_politique_latente", "Score de politisation", "0 = neutre, 100 = tr√®s politis√©"),
    ("position_strat√©gique", "Strat√©gie globale", "offensive, d√©fensive, ambigu√´‚Ä¶"),
    ("mode_d_interpellation_du_public", "Type d‚Äôinterpellation", "directe, p√©dagogique, √©motionnelle‚Ä¶"),
    ("figure_du_locuteur", "R√¥le du locuteur", "expert, citoyen, leader, victime‚Ä¶"),
    ("√©chelle_de_politisation", "Niveau d‚Äôancrage", "locale, nationale, internationale‚Ä¶"),
    ("type_de_menace_per√ßue", "Menace √©voqu√©e", "d√©clin, subversion, chaos‚Ä¶"),
    ("registre_moral_implicite", "Fond moral", "progressiste, conservateur, √©galitariste‚Ä¶"),
    ("ton_affectif_dominant", "√âmotion dominante", "col√®re, peur, espoir, fiert√©‚Ä¶"),
    ("niveau_de_certitude", "Certitude exprim√©e", "score 0-100 (incertitude ‚Üí affirmation)"),
    ("index_performativite", "Performativit√©", "0 = descriptif, 100 = incitation forte √† l‚Äôaction"),
    ("index_fanatisme", "Fermet√© id√©ologique", "0 = ouvert au d√©bat, 100 = hostile aux avis oppos√©s")
]

df_descr = pd.DataFrame(descripteurs, columns=["üß© Variable", "üóÇÔ∏è Description", "üîç Exemples ou √©chelle"])

# Encapsuler proprement
with st.expander("üìò Voir la liste d√©taill√©e des descripteurs analys√©s par le LLM", expanded=False):
    st.dataframe(df_descr, use_container_width=True, height=600)

# D√©marche analytique
st.markdown("""
---

### ‚öôÔ∏è D√©marche analytique

- Les variables **num√©riques** (ex: `charge_politique_latente`, `index_fanatisme`) sont standardis√©es via `StandardScaler`.
- Les variables **cat√©gorielles multilabels** (ex: *valeurs*, *figures ennemies*) sont vectoris√©es avec `MultiLabelBinarizer`.
- Ces vecteurs sont projet√©s dans un plan 2D avec `UMAP` (distance *cosine*), ce qui permet d‚Äôobserver des proximit√©s id√©ologiques latentes.

üé® Le **gradient de couleur** repr√©sente la politisation : plus il est √©lev√©, plus le discours est marqu√© politiquement.
""")

    # Chargement des donn√©es
    with st.spinner("‚è≥ Patientez quelques secondes le temps que le graphique charge :)"):
        df = pd.read_csv("results_df.csv")
        df = df.dropna(subset=["title", "charge_politique_latente"]).reset_index(drop=True)
    
        # Conversion des colonnes de listes depuis string (si n√©cessaire)
        list_cols = [
            "style_de_politisation",
            "figures_ennemies",
            "valeurs_invoqu√©es",
            "th√©matiques_dominantes"
        ]
    
        for col in list_cols:
            df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith('[') else [])
    
        # Colonnes num√©riques √† inclure
        numerical_cols = ["charge_politique_latente", "index_fanatisme"]
    
        # Encodage MultiLabel
        encoded_parts = []
        for col in list_cols:
            mlb = MultiLabelBinarizer()
            try:
                binarized = mlb.fit_transform(df[col])
                encoded_df = pd.DataFrame(binarized, columns=[f"{col}__{c}" for c in mlb.classes_])
                encoded_parts.append(encoded_df)
            except Exception as e:
                st.warning(f"Probl√®me d'encodage pour {col} : {e}")
    
        # Construction de la matrice finale
        X_num = df[numerical_cols].fillna(0).reset_index(drop=True)
        X_cat = pd.concat(encoded_parts, axis=1).reset_index(drop=True)
        X_all = pd.concat([X_num, X_cat], axis=1)
    
        # Normalisation
        X_scaled = StandardScaler().fit_transform(X_all)
    
        # UMAP
        umap = UMAP(n_neighbors=5, min_dist=0.1, metric="cosine", random_state=42)
        embedding = umap.fit_transform(X_scaled)
    
        # DataFrame pour visualisation
        df_visu = pd.DataFrame({
            "x": embedding[:, 0],
            "y": embedding[:, 1],
            "title": df["title"],
            "charge_politique_latente": df["charge_politique_latente"]
        })
    
        # Graphique Plotly
        fig = px.scatter(
            df_visu,
            x="x", y="y",
            text="title",
            color="charge_politique_latente",
            color_continuous_scale="RdBu_r",
            hover_name="title",
            title="Projection UMAP des cha√Ænes (gradient = charge politique latente)"
        )
        fig.update_traces(textposition='top center')
        fig.update_layout(height=700)
    
        st.plotly_chart(fig, use_container_width=True)
elif page == "üéµ NLP/LLM: Cartographier les artistes fran√ßais depuis les paroles de leur r√©pertoire.":
    st.markdown("""
    <div style="text-align: left; font-size: 18px; line-height: 1.6; margin-top: 20px;">
        <p><strong>Pr√©sentation du projet :</strong></p>
        <p>
            L'id√©e principale de ce projet est de pouvoir visualiser la distance ou la proximit√© entre les artistes musicaux fran√ßais, √† partir de leurs paroles.
        </p>
        <p>
            Gr√¢ce √† diff√©rents traitements de donn√©es depuis une API de paroles de musiques et un stockage en base de donn√©es, un embedding (une m√©thode pour repr√©senter dans un espace vectoriel du langage naturel) est r√©alis√© gr√¢ce au mod√®le de langage <strong> FlauBERT</strong>, 
            le graphique ci-dessous permet de visualiser cette proximit√© entre les artistes.
        </p>
        <p>
            La multi-dimensionnalit√© de l'espace vectoriel est r√©duite gr√¢ce √† une m√©thode de r√©duction de dimension (TSNE), afin d'√™tre visualisable en 2D. 
            <em>(Cette r√©duction implique que les axes n'ont pas de noms sp√©cifiques.)</em>
        </p>
        <p>
            On remarque qu'un groupe d'artistes se d√©marque du reste du corps d'artistes fran√ßais : ce sont les rappeurs.
        </p>
        <p>
            L'√©volution g√©n√©rationnelle dans l'√©criture se remarque √©galement par la distance entre les chanteurs les plus vieux et ceux les plus r√©cents, 
            mais on aper√ßoit √©galement des clivages entre des paroles "chant√©es" et des paroles "parl√©es", alors que l'analyse ne porte que sur les paroles ! 
        </p>
        <p>
            Tout l'enjeu de ce projet est le traitement des donn√©es et l'utilisation d'un mod√®le de langage adapt√©: il faut √† la fois un bon compromis co√ªt/performance, mais aussi √©tudier quel mod√®le de langage est le plus √† m√™me de saisir ce qui diff√©rencie un texte d'un autre.
     
    </div>
""", unsafe_allow_html=True)
    # Chargement des donn√©es
    file_path = 'artistes.parquet' 
    df = pd.read_parquet(file_path, columns=['artist_name', 'avg_embedding'])

    with st.spinner("‚è≥ Patientez quelques secondes le temps que le graphique charge :)"):
        if 'avg_embedding' not in df.columns:
            st.error('La colonne avg_embedding n\'existe pas dans le DataFrame.')
        else:
            # Extraction des noms d'artistes et des embeddings
            artists = df['artist_name'].tolist()
            embeddings = np.array(df['avg_embedding'].apply(ast.literal_eval).tolist())
    
            tabs = st.tabs(["Visualisation des Embeddings", "Clustering des Artistes", "Etude par Artiste"])
    
            # Onglet 1 : Visualisation des embeddings
            with tabs[0]:
                # Visualisation avec t-SNE
                def generate_espace_artistes():
                    reducer = TSNE(n_components=2, random_state=0)
                    reduced_embeddings = reducer.fit_transform(embeddings)
    
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        x=reduced_embeddings[:, 0],
                        y=reduced_embeddings[:, 1],
                        mode='markers',
                        marker=dict(size=8, color='blue'),
                        text=artists,
                        textposition='top center',
                        hoverinfo='none'
                    ))
    
                    for i, artist in enumerate(artists):
                        artist_url = f'/{artist}/'
                        fig.add_annotation(
                            x=reduced_embeddings[i, 0],
                            y=reduced_embeddings[i, 1],
                            text=f'<a href="{artist_url}" target="_blank">{artist}</a>',
                            showarrow=True,
                            arrowhead=2,
                            ax=20,
                            ay=-20,
                            font=dict(size=10, color='blue'),
                            align='center'
                        )
    
                    fig.update_layout(
                        autosize=True,
                        width=1800,
                        height=800,
                        title='Visualisation des Embeddings des Artistes avec Embeddings Moyens',
                        template='plotly_white',
                        margin=dict(l=50, r=50, t=100, b=50),
                        xaxis=dict(showgrid=True, zeroline=False),
                        yaxis=dict(showgrid=True, zeroline=False)
                    )
    
                    return fig
    
                fig = generate_espace_artistes()
                st.plotly_chart(fig, use_container_width=True)

            # Onglet 2 : Clustering des artistes
            with tabs[1]:
                st.write("Ce second graphique est le m√™me que le premier, mais met en avant diff√©rents clusters, c'est √† dire des groupements d'√©l√©ments semblables au regard des autres. On retrouve les diff√©rentes segmentations que l'on pr√©sentais, et m√™me une segmentation au sein m√™me du groupe des rappeurs")
                def cluster_artists(artist_vectors, n_clusters=5):
                    """Clustering des artistes en utilisant les vecteurs de leurs paroles."""
                    artist_names = list(artist_vectors.keys())
                    embeddings = np.array(list(artist_vectors.values()))
                    
                    kmeans = KMeans(n_clusters=n_clusters, random_state=0)
                    clusters = kmeans.fit_predict(embeddings)
                    
                    return artist_names, embeddings, clusters
    
                # Fonction pour visualiser les clusters en utilisant t-SNE
                def visualize_clusters_with_tsne(artist_names, embeddings, clusters):
                    """Visualiser les clusters d'artistes avec t-SNE."""
                    # R√©duction de dimensionnalit√© avec t-SNE
                    tsne = TSNE(n_components=2, random_state=0)
                    reduced_embeddings = tsne.fit_transform(embeddings)
                    
                    
                    fig = go.Figure()
                    color_scale = px.colors.qualitative.Plotly
    
                    fig.add_trace(go.Scatter(
                        x=reduced_embeddings[:, 0],
                        y=reduced_embeddings[:, 1],
                        mode='markers',
                        marker=dict(
                            size=12,
                            color=clusters,
                            colorscale=color_scale,
                            colorbar=None,
                            line=dict(width=2, color='DarkSlateGrey')
                        ),
                        hoverinfo='text',
                        hovertext=[f'Artiste: {name}<br>Cluster: {cluster}' for name, cluster in zip(artist_names, clusters)]
                    ))
    
                
                    annotations = []
                    for i, artist in enumerate(artist_names):
                        artist_url = f'/{artist}/'  # URL vers la page de l'artiste
                        annotations.append(dict(
                            x=reduced_embeddings[i, 0],
                            y=reduced_embeddings[i, 1],
                            text=f'<a href="{artist_url}" target="_blank">{artist}</a>',
                            showarrow=True,
                            arrowhead=2,
                            ax=20,
                            ay=-20,
                            font=dict(size=10, color='blue'),
                            align='center'
                        ))
    
            
                    fig.update_layout(
                        annotations=annotations,
                        title='Clustering des Artistes bas√©s sur les Embeddings des Paroles (t-SNE)',
                        xaxis_title='Composante 1',
                        yaxis_title='Composante 2',
                        showlegend=False,
                        template='plotly_white',
                        width=1800,
                        height=1000,
                        autosize=True,
                        margin=dict(l=50, r=50, t=100, b=50),
                        xaxis=dict(showgrid=True, zeroline=False),
                        yaxis=dict(showgrid=True, zeroline=False)
                    )
                    
                    return fig
    
           
                def load_and_visualize(df):
             
                    if 'avg_embedding' not in df.columns:
                        st.error('La colonne avg_embedding n\'existe pas dans le DataFrame.')
                        return
    
                    # Extraction des artistes et des embeddings
                    artist_vectors = {row['artist_name']: ast.literal_eval(row['avg_embedding']) for index, row in df.iterrows()}
                    
                    # Appliquer le clustering
                    n_clusters = 5  # Nombre de clusters
                    artist_names, embeddings, clusters = cluster_artists(artist_vectors, n_clusters)
                    
                    # Visualiser les clusters
                    fig = visualize_clusters_with_tsne(artist_names, embeddings, clusters)
                    st.plotly_chart(fig, use_container_width=True)
    
                # Appel de la fonction pour charger et visualiser les donn√©es
                load_and_visualize(df)
            # Onglet 3 : Autre contenu (ajoutez ici ce que vous souhaitez)
            # Onglet 3 : Autre contenu (ajoutez ici ce que vous souhaitez)
            with tabs[2]:
                st.write("Cette section est encore en d√©ploiement car elle implique un chargement trop long pour le moment ! ")
            #     # Charger les donn√©es
            #     df = pd.read_parquet('cluster.parquet')


        #     # Fonction pour r√©cup√©rer les titres, albums et embeddings d'un artiste
        #     def fetch_artist_lyrics(artist_name, df):
        #         # Filtrer le DataFrame pour l'artiste donn√©
        #         artist_data = df[df['artist_name'] == artist_name]
        #         titles = artist_data['song_title'].tolist()
        #         albums = artist_data['album_name'].tolist()
        #         embeddings = artist_data['embedded_lyrics'].tolist()  # Supposant que les embeddings sont stock√©s sous forme de liste

        #         # Convertir les cha√Ænes d'embeddings en listes
        #         embeddings = [ast.literal_eval(embedding) if isinstance(embedding, str) else embedding for embedding in embeddings]
        #         return titles, albums, embeddings

        #     # Fonction pour visualiser les chansons d'un artiste
        #     def visualize_artist_songs(artist_name, df, method='PCA'):
        #         titles, albums, embeddings = fetch_artist_lyrics(artist_name, df)

        #         # V√©rifier si les embeddings sont valides
        #         if len(embeddings) == 0 or any(len(embedding) == 0 for embedding in embeddings):
        #             return ''  # Si les embeddings sont vides, on ne fait rien

        #         # Convertir la liste de listes en tableau NumPy
        #         embeddings_array = np.array(embeddings)

        #         # R√©duction des dimensions
        #         if method == 'PCA':
        #             reducer = PCA(n_components=2)
        #         elif method == 't-SNE':
        #             reducer = TSNE(n_components=2, random_state=0)
        #         else:
        #             raise ValueError("M√©thode non reconnue. Utilisez 'PCA' ou 't-SNE'.")

        #         reduced_embeddings = reducer.fit_transform(embeddings_array)

        #         unique_albums = list(set(albums))
        #         color_map = {album: i for i, album in enumerate(unique_albums)}
        #         colors = [color_map[album] for album in albums]

        #         fig = go.Figure()
        #         color_scale = px.colors.qualitative.Plotly
        #         fig.add_trace(go.Scatter(
        #             x=reduced_embeddings[:, 0],
        #             y=reduced_embeddings[:, 1],
        #             mode='markers',
        #             marker=dict(
        #                 size=15,
        #                 color=colors,
        #                 colorscale=color_scale,
        #                 colorbar=dict(title='album_name'),
        #                 line=dict(width=2, color='DarkSlateGrey')
        #             ),
        #         ))

        #         # Ajouter des annotations avec des liens cliquables
        #         annotations = []
        #         for i, title in enumerate(titles):
        #             formatted_title = title.replace(" ", "_")
        #             annotations.append(dict(
        #                 x=reduced_embeddings[i, 0],
        #                 y=reduced_embeddings[i, 1],
        #                 text=f'<a href="/chanson/{artist_name}/{formatted_title}/" target="_blank">{title}</a>',
        #                 showarrow=True,
        #                 arrowhead=2,
        #                 ax=20,
        #                 ay=-20,
        #                 font=dict(size=10, color='black'),
        #                 align='center'
        #             ))

        #         fig.update_layout(
        #             title=f'Visualisation des Embeddings des Paroles - R√©pertoire de {artist_name}',
        #             xaxis_title='Composante 1',
        #             yaxis_title='Composante 2',
        #             showlegend=True,
        #             template='plotly_white',
        #             width=1500,
        #             height=900,
        #             autosize=True,
        #             margin=dict(l=50, r=50, t=100, b=50),
        #             annotations=annotations
        #         )

        #         return fig

        #     # Titre de l'application
        #     st.title("Visualisation des Chansons par Artiste")

            
        #     # S√©lectionner l'artiste dans un s√©lecteur
        #     artist_name = st.selectbox("Choisir un artiste", df['artist_name'].unique())

    
        #     if artist_name:
        #         # Visualiser les chansons de l'artiste
        #         fig = visualize_artist_songs(artist_name, df, 'PCA')
        #         st.plotly_chart(fig)
